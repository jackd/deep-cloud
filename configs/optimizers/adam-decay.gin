# optimizer settings used in pointnet code (paper stated decay_rate 0.5)
import more_keras.keras_configurables
import more_keras.schedules
import deep_cloud.gin_utils

optimizer_fn = @Adam
Adam.learning_rate = @optimizer/ExponentialDecayTowards()

optimizer/ExponentialDecayTowards.initial_learning_rate = 1e-3
optimizer/ExponentialDecayTowards.clip_value = 1e-5
optimizer/ExponentialDecayTowards.decay_steps = @optimizer/steps_in_examples()
optimizer/ExponentialDecayTowards.decay_rate = 0.7
optimizer/ExponentialDecayTowards.staircase = True

optimizer/steps_in_examples.num_examples = 200000
# steps_in_examples.batch_size = batch_size
